# -*- coding: utf-8 -*-
"""blister_train_MobileNetV2_Final1_2ndSept.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AlL5IihM3sXNMwrRYPJAuuT0am6cKqwM
"""

from __future__ import absolute_import, division, print_function, unicode_literals

!pip install tf-nightly-gpu-2.0-preview
import tensorflow as tf

import os
import numpy as np
import matplotlib.pyplot as plt
from keras.applications.mobilenet_v2 import preprocess_input, decode_predictions

"""# **Recognize tactile pavement using Transfer Learning**"""

tf.__version__

#@title Setup Input Pipeline

"""Accessing 2 classes of image data from google drive."""

from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

"""Use ImageDataGenerator to rescale the images.

Create the train generator and specify where the train dataset directory, image size, batch size.

Create the validation generator with similar approach as the train generator with the flow_from_directory() method.
"""

IMAGE_SIZE = 224
BATCH_SIZE = 64

datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255, 
    validation_split=0.2)

train_generator = datagen.flow_from_directory(
    '/content/gdrive/My Drive/blister_images/',
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE, 
    subset='training')

val_generator = datagen.flow_from_directory(
    '/content/gdrive/My Drive/blister_images/',
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE, 
    subset='validation')

"""## Create the base model from the pre-trained convnets

Create the base model from the MobileNet V2 model and pre-trained on the ImageNet dataset, a large dataset of 1.4M images and 1000 classes of web images.

First, pick which intermediate layer of MobileNet V2 will be used for feature extraction. A common practice is to use the output of the very last layer before the flatten operation, the so-called "bottleneck layer". The reasoning here is that the following fully-connected layers will be too specialized to the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.
"""

IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)

# Create the base model from the pre-trained model MobileNet V2
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                              include_top=False, 
                                              weights='imagenet')

"""## Feature extraction
You will freeze the convolutional base created from the previous step and use that as a feature extractor, add a classifier on top of it and train the top-level classifier.
"""

base_model.summary()

base_model.trainable = False

"""### Add a classification head"""

model = tf.keras.Sequential([
  base_model,
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(64, activation='relu'),
  tf.keras.layers.Dropout(0.2), 
  tf.keras.layers.Dense(2, activation='softmax')
])

"""### Compile the model"""

model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0002), 
              loss=tf.keras.losses.mean_absolute_error, 
              metrics=['accuracy'])

model.summary()

"""### Train the model

<!-- TODO(markdaoust): delete steps_per_epoch in TensorFlow r1.14/r2.0 -->
"""

epochs = 10

history = model.fit_generator(train_generator, 
                    epochs=epochs, 
                    validation_data=val_generator)

"""### Learning curves

Let's take a look at the learning curves of the training and validation accuracy/loss when using the MobileNet V2 base model as a fixed feature extractor.
"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

saved_model_dir = 'save/fine_tuning'
tf.saved_model.save(model, saved_model_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()

with open('model2.tflite', 'wb') as f:
  f.write(tflite_model)

import cv2

CATEGORIES = ["blister", "corduroy"]

def prepare (filepath):
  img_array = cv2.imread(filepath)
  new_array = cv2.resize(img_array,(IMAGE_SIZE,IMAGE_SIZE))
  plt.imshow(new_array)
  new_array=new_array.astype('float16')
  return new_array.reshape(-1, IMAGE_SIZE, IMAGE_SIZE,3)

prediction = model.predict([prepare('/content/gdrive/My Drive/blister_images/corduroy/average3.jpg')])
print(prediction)
# print(CATEGORIES[int(prediction[0][0])])

import cv2

CATEGORIES = ["blister", "corduroy"]

def prepare (filepath):
  img_array = cv2.imread(filepath)
  new_array = cv2.resize(img_array,(IMAGE_SIZE,IMAGE_SIZE))
  plt.imshow(new_array)
  new_array=new_array.astype('float16')
  return new_array.reshape(1, IMAGE_SIZE, IMAGE_SIZE,3)

prediction = model.predict([prepare('/content/gdrive/My Drive/blister_images/blister/average3.jpg')])
print(prediction)
# print(CATEGORIES[int(prediction[0][0])])

import cv2

CATEGORIES = ["blister", "corduroy"]

def prepare (filepath):
  img_array = cv2.imread(filepath)
  new_array = cv2.resize(img_array,(IMAGE_SIZE,IMAGE_SIZE))
  plt.imshow(new_array)
  new_array=new_array.astype('float16')
  return new_array.reshape(-1, IMAGE_SIZE, IMAGE_SIZE,3)

prediction = model.predict([prepare('/content/gdrive/My Drive/corduroytest/corduroy4.jpg')])
print(prediction)
# print(CATEGORIES[int(prediction[0][0])])

import cv2

CATEGORIES = ["blister", "corduroy"]

def prepare (filepath):
  img_array = cv2.imread(filepath)
  new_array = cv2.resize(img_array,(IMAGE_SIZE,IMAGE_SIZE))
  plt.imshow(new_array)
  new_array=new_array.astype('float16')
  return new_array.reshape(-1, IMAGE_SIZE, IMAGE_SIZE,3)

prediction = model.predict([prepare('/content/gdrive/My Drive/blistertest/blister3.jpg')])
print(prediction)
# print(CATEGORIES[int(prediction[0][0])])

import cv2

CATEGORIES = ["blister", "corduroy"]

def prepare (filepath):
  img_array = cv2.imread(filepath)
  new_array = cv2.resize(img_array,(IMAGE_SIZE,IMAGE_SIZE))
  plt.imshow(new_array)
  new_array=new_array.astype('float16')
  return new_array.reshape(-1, IMAGE_SIZE, IMAGE_SIZE,3)

prediction = model.predict([prepare('/content/gdrive/My Drive/blistertest/blister1.jpg')])
print(prediction)
# print(CATEGORIES[int(prediction[0][0])])

import cv2

CATEGORIES = ["blister", "corduroy"]

def prepare (filepath):
  img_array = cv2.imread(filepath)
  new_array = cv2.resize(img_array,(IMAGE_SIZE,IMAGE_SIZE))
  plt.imshow(new_array)
  new_array=new_array.astype('float16')
  return new_array.reshape(-1, IMAGE_SIZE, IMAGE_SIZE,3)

prediction = model.predict([prepare('/content/gdrive/My Drive/corduroytest/corduroy3.jpg')])
print(prediction)
# print(CATEGORIES[int(prediction[0][0])])

